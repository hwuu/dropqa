"""Agentic RAG Prompt 模板"""


# 查询改写 Prompt
QUERY_REWRITE_PROMPT = """你是一个查询分析助手，负责将用户的自然语言问题转换为更适合搜索的形式。

请分析用户的问题，并返回以下 JSON 格式的结果（不要输出其他内容）：

```json
{{
  "keywords": ["关键词1", "关键词2", ...],
  "fulltext_query": "适合全文搜索的查询",
  "semantic_query": "适合语义/向量搜索的查询"
}}
```

说明：
1. keywords: 提取问题中的核心关键词，用于精确匹配
2. fulltext_query: 改写为适合全文搜索的形式，保留重要术语
3. semantic_query: 改写为更自然的语义表达，便于向量搜索

用户问题：{question}

请直接返回 JSON 结果："""


# 多轮检索评估 Prompt
RETRIEVAL_EVALUATION_PROMPT = """你是一个检索质量评估助手。请评估当前检索结果是否足以回答用户问题。

用户问题：{question}

当前检索到的内容：
{contexts}

请分析检索结果是否充分，返回以下 JSON 格式（不要输出其他内容）：

```json
{{
  "is_sufficient": true/false,
  "reason": "判断理由",
  "supplementary_queries": ["补充查询1", "补充查询2"]
}}
```

说明：
1. is_sufficient: 如果当前结果足以回答问题，返回 true
2. reason: 简要说明判断理由
3. supplementary_queries: 如果不充分，给出 1-2 个补充查询（如果充分则为空数组）

请直接返回 JSON 结果："""


# 结果重排序 Prompt
RERANK_PROMPT = """你是一个相关性评估助手。请评估以下检索结果与用户问题的相关性。

用户问题：{question}

检索结果（按原始顺序）：
{candidates}

请为每个结果评估相关性分数（0-10 分），返回以下 JSON 格式（不要输出其他内容）：

```json
{{
  "scores": [
    {{"id": "结果ID", "score": 分数, "reason": "简短理由"}},
    ...
  ]
}}
```

评分标准：
- 9-10: 直接回答问题的核心内容
- 7-8: 与问题高度相关，提供重要信息
- 4-6: 部分相关，可能有帮助
- 1-3: 弱相关或边缘相关
- 0: 完全不相关

重要提示：
1. 如果问题是概念性的（如"是什么"、"有哪些功能"），则概述/介绍类内容应高分，纯代码/命令行内容应低分
2. 如果问题是操作性的（如"怎么启动"、"如何配置"），则具体命令/代码应高分
3. 只有直接能帮助回答问题的内容才应该得高分

请直接返回 JSON 结果："""
